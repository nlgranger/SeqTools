{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden",
    "outputs_hidden": true,
    "source_hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "from unittest import mock\n",
    "\n",
    "orig_stack = inspect.stack\n",
    "\n",
    "def stack():\n",
    "    s = orig_stack()\n",
    "    i = len(s) - 1\n",
    "    while i > 0 and not s[i][1].startswith(\"<ipython-input\"):\n",
    "        i -= 1\n",
    "    \n",
    "    return s[:i + 1]\n",
    "\n",
    "inspect.stack = stack\n",
    "\n",
    "with mock.patch('seqtools.errors.inspect', inspect):\n",
    "    import seqtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error handling and debuging\n",
    "\n",
    "During the design of a transformation pipeline, mistakes and programming errors are relatively frequent.\n",
    "SeqTools tries to recover from them and report useful informations as much as possible.\n",
    "This tutorial reviews some details about the internal error management and should facilitate your debugging sessions.\n",
    "\n",
    "\n",
    "## Tracing mapping errors\n",
    "\n",
    "Due to on-demand execution, an error generated by mapping a function to a dataset will only happen when a problematic element is read, not when the data container is defined.\n",
    "\n",
    "By default, SeqTools raises an `EvaluationError` in such cases, and sets the original exception as its cause.\n",
    "Let's observe this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import seqtools\n",
    "\n",
    "def f1(x):\n",
    "    return math.sqrt(x)  # this will fail for negative values\n",
    "\n",
    "def f2(x):\n",
    "    return x + 1\n",
    "\n",
    "data = [random.randint(0, 100) for _ in range(100)]\n",
    "data[-1] *= -1\n",
    "\n",
    "out = seqtools.smap(f1, data)\n",
    "out = seqtools.smap(f2, out)\n",
    "out = seqtools.smap(f1, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to on-demand execution, we are still unaware of the upcoming failure for the last item.\n",
    "But when we evaluate the items..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "list(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ValueError` that caused the failure is detailed first.\n",
    "Unfortunately, the origin of the error is ambiguous because `f1` is used twice in this pipeline.\n",
    "To alleviate this issue, the exception message of the resulting `EvaluationError` provides additional clarifications: it tells where the failing mapping was defined, here on the first mapping of `f1`.\n",
    "\n",
    "If you prefer working with the original directly and skip the `EvaluationError`, you can enable the _'passthrough'_ error mode which does just that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtools.seterr(evaluation='passthrough')\n",
    "\n",
    "list(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtools.seterr(evaluation='wrap')  # revert to normal behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors inside worker\n",
    "\n",
    "Background workers used by `prefetch` or `load_buffers` do not share the execution space of the main program.\n",
    "As a result, exceptions raised while evaluating an element inside a worker happen asynchronously and separately from the main program.\n",
    "\n",
    "To hide this aspect from end-users, SeqTools tries to store errors and report them when appropriate.\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "fast_out = seqtools.prefetch(out, max_buffered=10)\n",
    "\n",
    "# evaluate all elements normally\n",
    "for i in range(len(fast_out) - 1):\n",
    "    fast_out[i]\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All valid elements were read normally.\n",
    "By waiting one extra second, we are now certain that the final element has been evaluated (and raised a `ValueException`), but no error is raised until an explicit read is attempted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_out[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the workers will continue working just fine after the error.\n",
    "If desired, you can catch the exception and continue reading other values.\n",
    "\n",
    "This approach greatly facilitates debugging but has limitations to be aware of:\n",
    "\n",
    "- Process-based workers cannot save errors that cannot be pickled, in particular exception types defined inside a function.\n",
    "- Error tracebacks must be saved and then reconstructed. Some information is lost during this process and you won't be able to navigate inside the execution stack with a debugger."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
